from pyspark.sql import SparkSession
from pyspark.sql.functions import explode, split, regexp_replace, col, lower, length, trim

# inicia a sessao do Spar
spark_session = SparkSession.builder.appName("WordCount").getOrCreate()

#  CARREGARRADME.md
readme_file = spark_session.read.text("README.md")

# remove num e caracteres especiais mas mantém letras com acento converte tudo para minuscula
clean_text = readme_file.select(regexp_replace(lower(col("value")), "[^a-zA-Z\\sà-úÀ-Ú]", " ").alias("cleaned_value"))

# dvide o texto em palavras
palavras = clean_text.select(explode(split(clean_text.cleaned_value, "\\s+")).alias("palavra"))

# remove palavras vazias letras isoladas e palavras curtas
palavras = palavras.filter((col("palavra") != "") & (length(col("palavra")) > 2))

# remove espacos em branco das palavras
palavras = palavras.withColumn("palavra", trim(col("palavra")))

# conta quantas vezes cada palavra aparece
contagem_palavras = palavras.groupBy("palavra").count()

# mostra o resultado na tela
contagem_palavras.show(truncate=False, n=100)

# calcula o total de caracteres sem contar os espaços
char_count = clean_text.select(length(regexp_replace(col("cleaned_value"), "\\s", "")).alias("char_count")).groupBy().sum().collect()[0][0]

print(f"Total de caracteres (sem espaços em branco): {char_count}")

# Salva o resultado num arquivo CSV
contagem_palavras.coalesce(1).write.mode("overwrite").format("csv").option("header", "true").save("contagem_palavras_output")

# Renomeia o arquivo CSV pra .txt
import os
os.system("mv contagem_palavras_output/part-00000-*.csv contagem_palavras.txt")

