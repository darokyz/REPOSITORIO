import random
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Exercicio Etapa 1").getOrCreate()

numeros_aleatorios = [random.randint(1, 1000) for _ in range(250)]

rdd = spark.sparkContext.parallelize(numeros_aleatorios)

rdd_reverso = rdd.sortBy(lambda x: -numeros_aleatorios.index(x))

print("Números na ordem reversa:")
print(rdd_reverso.collect())

# Números na ordem reversa:
#[417, 512, 131, 865, 284, 736, 28, 58, 970, 527, 908, 315, 716, 820, 366, 945, 785, 159, 686, 642, 180, 931, 383, 951, 232, 880, 267, 382, 187, 776, 97, 290, 358, 679, 878, 85, 158, 181, 655, 748, 488, 722, 728, 430, 164, 30, 584, 744, 9, 327, 557, 556, 640, 806, 337, 966, 298, 124, 319, 956, 917, 129, 914, 629, 437, 413, 59, 56, 177, 175, 923, 719, 521, 521, 183, 26, 768, 751, 280, 280, 702, 134, 733, 436, 378, 291, 602, 550, 550, 49, 287, 287, 345, 969, 153, 786, 256, 202, 336, 705, 641, 237, 306, 446, 238, 238, 238, 754, 829, 514, 432, 404, 323, 323, 855, 723, 783, 613, 613, 558, 475, 475, 475, 911, 524, 459, 165, 448, 837, 750, 480, 262, 262, 627, 627, 959, 952, 952, 348, 340, 665, 564, 534, 889, 479, 197, 859, 593, 468, 110, 214, 893, 334, 34, 412, 697, 227, 620, 269, 393, 685, 901, 643, 529, 529, 145, 145, 834, 944, 814, 777, 777, 522, 781, 400, 65, 799, 376, 376, 746, 881, 163, 163, 699, 281, 544, 544, 213, 213, 601, 601, 338, 552, 176, 161, 466, 356, 109, 509, 891, 333, 987, 101, 844, 771, 473, 473, 710, 239, 226, 688, 894, 894, 55, 632, 236, 236, 978, 672, 672, 142, 991, 127, 294, 294, 997, 986, 492, 351, 749, 549, 549, 714, 170, 943, 943, 603, 94, 94, 212, 1000, 946, 8, 500, 657, 657, 725, 740, 850, 266]